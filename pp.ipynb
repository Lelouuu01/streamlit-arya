{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Machine Learning: Prediksi Rating Sepatu Pria\n",
    "\n",
    "Notebook ini berisi pipeline lengkap untuk analisis dan pemodelan machine learning pada dataset sepatu pria. Langkah-langkah yang akan dilakukan meliputi:\n",
    "\n",
    "1.  **Eksplorasi Data (EDA)**: Memahami distribusi dan korelasi data.\n",
    "2.  **Preprocessing Data**: Membersihkan, melakukan imputasi, encoding, dan scaling.\n",
    "3.  **Pembagian Dataset**: Memisahkan data menjadi set training dan testing.\n",
    "4.  **Pelatihan Model**: Melatih minimal 3 algoritma (Regresi dan Klasifikasi).\n",
    "5.  **Evaluasi Model**: Menganalisis performa dengan metrik yang sesuai (Classification Report & metrik regresi).\n",
    "6.  **Visualisasi Performa**: Membandingkan kinerja antar model.\n",
    "7.  **Hyperparameter Tuning**: Mencari parameter terbaik untuk model.\n",
    "8.  **Cross-Validation**: Memvalidasi ketahanan (robustness) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 1: Setup dan Import Library\n",
    "Pertama, kita akan mengimpor semua library yang dibutuhkan untuk analisis ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, accuracy_score\n",
    "\n",
    "# Konfigurasi untuk visualisasi dan output\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 2: Memuat dan Membersihkan Data\n",
    "Kita akan memuat dataset `MEN_SHOES.csv`, membersihkan kolom harga dari simbol mata uang, dan mengisi nilai yang hilang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('MEN_SHOES.csv')\n",
    "    print(\"Dataset berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: File 'MEN_SHOES.csv' tidak ditemukan. Pastikan file berada di direktori yang sama.\")\n",
    "\n",
    "# Buat salinan untuk menjaga data asli\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Hapus simbol mata uang '₹' dan koma ',' dari kolom harga\n",
    "df_cleaned['Current_Price'] = df_cleaned['Current_Price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Hapus koma ',' dari kolom penjualan\n",
    "df_cleaned['How_Many_Sold'] = df_cleaned['How_Many_Sold'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Imputasi nilai yang hilang di kolom harga dengan median\n",
    "median_price = df_cleaned['Current_Price'].median()\n",
    "df_cleaned['Current_Price'].fillna(median_price, inplace=True)\n",
    "\n",
    "print(\"\\nData setelah dibersihkan:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 3: Exploratory Data Analysis (EDA)\n",
    "Visualisasi data untuk memahami distribusi dan hubungan antar fitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Histogram untuk fitur numerik\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "sns.histplot(df_cleaned['Current_Price'], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribusi Harga (Current_Price)')\n",
    "\n",
    "sns.histplot(df_cleaned['How_Many_Sold'], bins=30, kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribusi Jumlah Terjual (How_Many_Sold)')\n",
    "\n",
    "sns.histplot(df_cleaned['RATING'], bins=20, kde=True, ax=axes[2])\n",
    "axes[2].set_title('Distribusi Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Boxplot untuk melihat outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "sns.boxplot(y=df_cleaned['Current_Price'], ax=axes[0])\n",
    "axes[0].set_title('Boxplot Harga')\n",
    "\n",
    "sns.boxplot(y=df_cleaned['How_Many_Sold'], ax=axes[1])\n",
    "axes[1].set_title('Boxplot Jumlah Terjual')\n",
    "\n",
    "sns.boxplot(y=df_cleaned['RATING'], ax=axes[2])\n",
    "axes[2].set_title('Boxplot Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Heatmap Korelasi\n",
    "plt.figure(figsize=(10, 8))\n",
    "numerical_cols = df_cleaned.select_dtypes(include=np.number)\n",
    "correlation_matrix = numerical_cols.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap Korelasi Antar Fitur Numerik')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 4: Preprocessing dan Pembagian Dataset\n",
    "Sekarang kita akan menyiapkan data untuk pemodelan:\n",
    "1.  **Definisi Fitur (X) dan Target (y)**: Kita akan membuat dua target, satu untuk regresi (`y_reg`) dan satu untuk klasifikasi (`y_clf`).\n",
    "2.  **Preprocessing Pipeline**: Membuat `ColumnTransformer` untuk melakukan scaling pada fitur numerik dan encoding pada fitur kategorikal. **Penting**: `sparse_output=False` ditambahkan untuk mengatasi error pada model `GaussianNB`.\n",
    "3.  **Pembagian Data**: Membagi data menjadi 80% training dan 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definisi Fitur (X) dan Target (y)\n",
    "X = df_cleaned.drop(columns=['RATING', 'Product_details'])\n",
    "y_reg = df_cleaned['RATING'] # Target untuk regresi\n",
    "\n",
    "# Buat target untuk klasifikasi dengan mengubah rating menjadi kategori\n",
    "y_clf = pd.cut(df_cleaned['RATING'], \n",
    "               bins=[0, 3.8, 4.0, 5], \n",
    "               labels=['Buruk', 'Rata-rata', 'Baik'], \n",
    "               include_lowest=True).fillna('Rata-rata')\n",
    "\n",
    "# 2. Preprocessing Pipeline\n",
    "numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "categorical_features = ['Brand_Name']\n",
    "\n",
    "# **PENTING**: sparse_output=False untuk memastikan output dari preprocessor adalah dense array\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# 3. Pembagian Data\n",
    "# Untuk Regresi\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Untuk Klasifikasi\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_clf, test_size=0.2, random_state=42, stratify=y_clf)\n",
    "\n",
    "print(f\"Ukuran data training untuk klasifikasi: {X_train_clf.shape}\")\n",
    "print(f\"Ukuran data testing untuk klasifikasi: {X_test_clf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 5 & 6: Pelatihan dan Evaluasi Model\n",
    "Kita akan melatih semua model yang dipilih pada data training dan mengevaluasi performanya pada data testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Model Regresi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "    'Support Vector Regressor (SVR)': SVR()\n",
    "}\n",
    "\n",
    "print(\"--- EVALUASI MODEL REGRESI ---\")\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    # Buat pipeline lengkap dengan preprocessor dan model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X_train_reg, y_train_reg)\n",
    "    y_pred = pipeline.predict(X_test_reg)\n",
    "\n",
    "    # Evaluasi\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"  R-squared (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Model Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors (KNN)': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"--- LAPORAN KINERJA MODEL KLASIFIKASI ---\")\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    pipeline.fit(X_train_clf, y_train_clf)\n",
    "    y_pred = pipeline.predict(X_test_clf)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"MODEL: {name}\")\n",
    "    print(f\"AKURASI: {accuracy:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_test_clf, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 7: Visualisasi Performa Model\n",
    "Membuat diagram batang untuk membandingkan performa dari semua model secara visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi akan dibuat pada langkah terakhir untuk membandingkan model dasar, setelah tuning, dan cross-validation.\n",
    "# Untuk saat ini, kita bisa simpan hasilnya untuk perbandingan nanti.\n",
    "\n",
    "# Namun, mari kita buat visualisasi awal untuk model dasar.\n",
    "reg_perf = {}\n",
    "for name, model in regression_models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X_train_reg, y_train_reg)\n",
    "    y_pred = pipeline.predict(X_test_reg)\n",
    "    reg_perf[name] = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "clf_perf = {}\n",
    "for name, model in classification_models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    pipeline.fit(X_train_clf, y_train_clf)\n",
    "    y_pred = pipeline.predict(X_test_clf)\n",
    "    clf_perf[name] = accuracy_score(y_test_clf, y_pred)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 7))\n",
    "pd.Series(reg_perf).sort_values().plot(kind='barh', ax=ax[0], title='Perbandingan Model Regresi (R-squared)')\n",
    "ax[0].set_xlabel('R-squared Score')\n",
    "\n",
    "pd.Series(clf_perf).sort_values().plot(kind='barh', ax=ax[1], title='Perbandingan Model Klasifikasi (Accuracy)')\n",
    "ax[1].set_xlabel('Accuracy Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 8: Hyperparameter Tuning\n",
    "Kita akan mengambil model klasifikasi dengan performa terbaik (berdasarkan akurasi) dan mencoba mencari kombinasi hyperparameter yang lebih optimal menggunakan `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cari nama model klasifikasi dengan akurasi tertinggi\n",
    "best_clf_name = max(clf_perf, key=clf_perf.get)\n",
    "print(f\"Model klasifikasi terbaik adalah: {best_clf_name} dengan akurasi awal {clf_perf[best_clf_name]:.4f}\\n\")\n",
    "\n",
    "# Definisikan pipeline dan parameter grid untuk model terbaik\n",
    "best_model_pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                                      ('classifier', classification_models[best_clf_name])])\n",
    "\n",
    "param_grid = {}\n",
    "if 'Decision Tree' in best_clf_name:\n",
    "    param_grid = {\n",
    "        'classifier__max_depth': [5, 10, 15, None],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "elif 'KNN' in best_clf_name:\n",
    "    param_grid = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "# Lakukan Grid Search jika modelnya bukan Gaussian NB\n",
    "if param_grid:\n",
    "    grid_search = GridSearchCV(best_model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train_clf, y_train_clf)\n",
    "    \n",
    "    print(f\"Tuning Model: {best_clf_name}\")\n",
    "    print(f\"Parameter Terbaik: {grid_search.best_params_}\")\n",
    "    print(f\"Akurasi Terbaik (setelah tuning): {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Simpan model terbaik setelah tuning\n",
    "    best_model_after_tuning = grid_search.best_estimator_\n",
    "else:\n",
    "    print(f\"{best_clf_name} tidak memiliki hyperparameter umum untuk dituning dalam skenario ini.\")\n",
    "    best_model_after_tuning = best_model_pipeline.fit(X_train_clf, y_train_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Langkah 9: Cross-Validation\n",
    "Terakhir, kita akan menerapkan cross-validation pada model terbaik untuk memastikan performanya stabil dan tidak hanya kebetulan bagus pada satu pembagian data saja (robustness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- CROSS-VALIDATION UNTUK ROBUSTNESS ---\")\n",
    "\n",
    "# CV untuk model regresi terbaik (berdasarkan R2 awal)\n",
    "best_reg_name = max(reg_perf, key=reg_perf.get)\n",
    "pipeline_reg_cv = Pipeline(steps=[('preprocessor', preprocessor), ('model', regression_models[best_reg_name])])\n",
    "cv_scores_reg = cross_val_score(pipeline_reg_cv, X, y_reg, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation untuk Regresi: {best_reg_name}\")\n",
    "print(f\"  Skor R2 (per fold): {np.round(cv_scores_reg, 4)}\")\n",
    "print(f\"  Rata-rata R2: {cv_scores_reg.mean():.4f} (+/- {cv_scores_reg.std():.4f})\\n\")\n",
    "\n",
    "# CV untuk model klasifikasi terbaik setelah tuning\n",
    "cv_scores_clf = cross_val_score(best_model_after_tuning, X, y_clf, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation untuk Klasifikasi: {best_clf_name} (Setelah Tuning)\")\n",
    "print(f\"  Skor Akurasi (per fold): {np.round(cv_scores_clf, 4)}\")\n",
    "print(f\"  Rata-rata Akurasi: {cv_scores_clf.mean():.4f} (+/- {cv_scores_clf.std():.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}